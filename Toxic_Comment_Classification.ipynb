{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfXH4yk/GUiVAPwmOPYSSl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2003UJAN/Toxic-Comment-Classification/blob/main/Toxic_Comment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Packages**"
      ],
      "metadata": {
        "id": "HKOaUc1Uq6Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from statistics import mean\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "import statistics\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "C46b4Gb2rUib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading & Pre-Processing**"
      ],
      "metadata": {
        "id": "EWLROUturbkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"data/train.csv\")\n",
        "test = pd.read_csv(\"data/test.csv\")\n",
        "test_y = pd.read_csv(\"data/test_labels.csv\")"
      ],
      "metadata": {
        "id": "ko3OwfXosLY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "_MlqPhi6sTfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "metadata": {
        "id": "f3yLdBt-sUWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "qhJ0rUDMsYEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_y.head()"
      ],
      "metadata": {
        "id": "MuTieIK1sgpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "id": "U6YPJJwSsjEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "id": "7XVZU0dcslfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(color_codes=True)\n",
        "comment_len = train.comment_text.str.len()\n",
        "sns.distplot(comment_len, kde=False, bins=20, color=\"steelblue\")"
      ],
      "metadata": {
        "id": "wFxxJ5lPsntv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsetting labels from the training data\n",
        "train_labels = train[['toxic', 'severe_toxic',\n",
        "                      'obscene', 'threat', 'insult', 'identity_hate']]\n",
        "label_count = train_labels.sum()"
      ],
      "metadata": {
        "id": "pBHQ2E27stCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_count.plot(kind='bar', title='Labels Frequency', color='steelblue')"
      ],
      "metadata": {
        "id": "ziwmy_oNsvmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to draw bar graph for visualising distribution of classes within each label.\n",
        "barWidth = 0.25\n",
        "\n",
        "bars1 = [sum(train['toxic'] == 1), sum(train['obscene'] == 1), sum(train['insult'] == 1), sum(train['severe_toxic'] == 1),\n",
        "         sum(train['identity_hate'] == 1), sum(train['threat'] == 1)]\n",
        "bars2 = [sum(train['toxic'] == 0), sum(train['obscene'] == 0), sum(train['insult'] == 0), sum(train['severe_toxic'] == 0),\n",
        "         sum(train['identity_hate'] == 0), sum(train['threat'] == 0)]\n",
        "\n",
        "r1 = np.arange(len(bars1))\n",
        "r2 = [x + barWidth for x in r1]\n",
        "\n",
        "plt.bar(r1, bars1, color='steelblue', width=barWidth, label='labeled = 1')\n",
        "plt.bar(r2, bars2, color='lightsteelblue', width=barWidth, label='labeled = 0')\n",
        "\n",
        "plt.xlabel('group', fontweight='bold')\n",
        "plt.xticks([r + barWidth for r in range(len(bars1))], ['Toxic', 'Obscene', 'Insult', 'Severe Toxic', 'Identity Hate',\n",
        "                                                       'Threat'])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1hOuyAZMsyf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of clean comment\n",
        "train.comment_text[0]"
      ],
      "metadata": {
        "id": "_06p_J4qwMSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of toxic comment\n",
        "train[train.toxic == 1].iloc[1, 1]"
      ],
      "metadata": {
        "id": "Cj2YxqD_wOig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross correlation matrix across labels\n",
        "rowsums = train.iloc[:, 2:].sum(axis=1)\n",
        "temp = train.iloc[:, 2:-1]\n",
        "train_corr = temp[rowsums > 0]\n",
        "corr = train_corr.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr,\n",
        "            xticklabels=corr.columns.values,\n",
        "            yticklabels=corr.columns.values, annot=True, cmap=\"Blues\""
      ],
      "metadata": {
        "id": "mKODhILpwRF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def W_Cloud(token):\n",
        "    \"\"\"\n",
        "    Visualize the most common words contributing to the token.\n",
        "    \"\"\"\n",
        "    threat_context = train[train[token] == 1]\n",
        "    threat_text = threat_context.comment_text\n",
        "    neg_text = pd.Series(threat_text).str.cat(sep=' ')\n",
        "    wordcloud = WordCloud(width=1600, height=800,\n",
        "                          max_font_size=200).generate(neg_text)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(wordcloud.recolor(colormap=\"Blues\"), interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Most common words assosiated with {token} comment\", size=20)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hTX5t0ECwUSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interactive visual : enter the label name.\n",
        "token = input(\n",
        "    'Choose a class to visualize the most common words contributing to the class:')\n",
        "W_Cloud(token.lower())"
      ],
      "metadata": {
        "id": "1OBFkGTGwYWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "aB37ecrTxDTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = [\"toxic\", \"severe_toxic\", \"obscene\",\n",
        "               \"threat\", \"insult\", \"identity_hate\"]"
      ],
      "metadata": {
        "id": "U37McgNAxIGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    '''\n",
        "    Tokenize text and return a non-unique list of tokenized words found in the text.\n",
        "    Normalize to lowercase, strip punctuation, remove stop words, filter non-ascii characters.\n",
        "    Lemmatize the words and lastly drop words of length < 3.\n",
        "    '''\n",
        "    text = text.lower()\n",
        "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
        "    nopunct = regex.sub(\" \", text)\n",
        "    words = nopunct.split(' ')\n",
        "    # remove any non ascii\n",
        "    words = [word.encode('ascii', 'ignore').decode('ascii') for word in words]\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    words = [lmtzr.lemmatize(w) for w in words]\n",
        "    words = [w for w in words if len(w) > 2]\n",
        "    return words"
      ],
      "metadata": {
        "id": "fWR1RtLRxKWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = TfidfVectorizer(ngram_range=(1, 1), analyzer='word',\n",
        "                         tokenizer=tokenize, stop_words='english',\n",
        "                         strip_accents='unicode', use_idf=1, min_df=10)\n",
        "X_train = vector.fit_transform(train['comment_text'])\n",
        "X_test = vector.transform(test['comment_text'])"
      ],
      "metadata": {
        "id": "Mtt5LfDqxPLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.get_feature_names()[0:20]"
      ],
      "metadata": {
        "id": "WFviZqO8xP1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "BaOGlbZxxU1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating classifiers with default parameters initially.\n",
        "clf1 = MultinomialNB()\n",
        "clf2 = LogisticRegression()\n",
        "clf3 = LinearSVC()"
      ],
      "metadata": {
        "id": "Sz3_npNfxY1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation_score(classifier, X_train, y_train):\n",
        "    '''\n",
        "    Iterate though each label and return the cross validation F1 and Recall score\n",
        "    '''\n",
        "    methods = []\n",
        "    name = classifier.__class__.__name__.split('.')[-1]\n",
        "\n",
        "    for label in test_labels:\n",
        "        recall = cross_val_score(\n",
        "            classifier, X_train, y_train[label], cv=10, scoring='recall')\n",
        "        f1 = cross_val_score(classifier, X_train,\n",
        "                             y_train[label], cv=10, scoring='f1')\n",
        "        methods.append([name, label, recall.mean(), f1.mean()])\n",
        "\n",
        "    return methods"
      ],
      "metadata": {
        "id": "ZCfJlzjNxde2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}